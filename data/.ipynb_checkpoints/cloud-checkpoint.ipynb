{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    div.output_area img {\n",
       "        max-width: 60em;\n",
       "        margin: auto;\n",
       "        display: block;\n",
       "        object-fit: contain;\n",
       "    }\n",
       "    table.dataframe {\n",
       "        margin: auto;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./../../setup.py\n",
    "ds = Dataset('object_detection/photoscan_projects/rmz_nexity/photoscan/cloud_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy as laspy\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_normalized_blocks(path, num_points):\n",
    "    files = os.listdir(path)\n",
    "    source_file = []\n",
    "    normalized_blocks = N.zeros((0,num_points,3))\n",
    "    block_min_array = N.zeros((0,3))\n",
    "    block_max_array = N.zeros((0,3))\n",
    "    for file in files:\n",
    "        inFile = laspy.file.File(os.path.join(path,file), mode = 'r')\n",
    "        unscaled_points = N.vstack([inFile.X, inFile.Y, inFile.Z]).transpose()\n",
    "        if(len(list(unscaled_points))>=num_points):\n",
    "            head = inFile.header\n",
    "            scale = head.scale\n",
    "            offset = head.offset\n",
    "            points = unscaled_points * scale + offset\n",
    "            \n",
    "            #sample\n",
    "            random_indexes = N.random.randint(0, high=len(points)-1, size=num_points)\n",
    "            block = points[random_indexes]\n",
    "            \n",
    "            #normalize\n",
    "            block_min = N.min(block ,axis = 0)\n",
    "            block_max = N.max(block ,axis = 0)\n",
    "            points_sub = block - block_min\n",
    "            diff = block_max - block_min\n",
    "            n_block = points_sub/diff\n",
    "            normalized_blocks = N.append(normalized_blocks,[n_block],axis=0)\n",
    "            block_min_array = N.append(block_min_array,[block_min],axis=0)\n",
    "            block_max_array = N.append(block_max_array,[block_max],axis=0)\n",
    "            source_file.append(file)\n",
    "                                    \n",
    "    return normalized_blocks,source_file,block_min_array,block_max_array   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file has string data!!!!\n",
    "\n",
    "def write_block_to_h5(filename, data, file, block_min_array, block_max_array):\n",
    "    hf = h5py.File(filename, 'w')\n",
    "    hf.create_dataset('data', data=data)\n",
    "    asciiList = [n.encode(\"ascii\", \"ignore\") for n in file]\n",
    "    string_type = h5py.special_dtype(vlen=bytes)\n",
    "    hf.create_dataset('source_file', shape = (len(asciiList),1), data = asciiList, dtype=string_type)\n",
    "    hf.create_dataset('min',data = block_min_array)\n",
    "    hf.create_dataset('max',data = block_max_array)\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBlockData(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    files = f['source_file'][:]\n",
    "    return (data, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_block(filename, query_x, query_y):\n",
    "    f = h5py.File(filename)\n",
    "    files = f['source_file'][:]\n",
    "    min_data = f['min'][:]\n",
    "    max_data = f['max'][:]\n",
    "    for i in range(min_data.shape[0]):\n",
    "        if(min_data[i][0]<query_x<max_data[i][0] and min_data[i][1]<query_y<max_data[i][1]):\n",
    "            print(files[i][0].decode(\"utf-8\"))\n",
    "            return files[i][0].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3248, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "num_points = 1024\n",
    "normalized_blocks, source_file, block_min_array, block_max_array = create_normalized_blocks(ds.path(),num_points)\n",
    "print(normalized_blocks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_block_to_h5('block_rmz.h5',normalized_blocks,source_file,block_min_array, block_max_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3248, 1024)\n"
     ]
    }
   ],
   "source": [
    "block_df = P.read_pickle('feature_0.pkl')\n",
    "feature = block_df['feature']\n",
    "feature_array = N.load('feature_0.npy')\n",
    "print(feature_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_5-29-40.las\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/research-disk/virtualenvs/tf-cpu1/lib/python3.6/site-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "query_x = 5066.547\n",
    "query_y = 7834.452\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "#tree = KDTree(block_df['feature'].as_matrix())  \n",
    "tree = KDTree(feature_array)\n",
    "block_file = find_block('block_rmz.h5',query_x, query_y)\n",
    "index = block_df['file'] == block_file\n",
    "dist, ind = tree.query(feature_array[index].reshape(1,-1), k=10)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2793  985 1374 1066 1266 2022 2460 3189  286 2451]]\n"
     ]
    }
   ],
   "source": [
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_files = list(block_df['file'][ind[0]])\n",
    "for file in nn_files:\n",
    "    inFile = laspy.file.File(os.path.join(ds.path(),file), mode = 'r')\n",
    "    unscaled_points = N.vstack([inFile.X, inFile.Y, inFile.Z]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pc_util\n",
    "import imageio\n",
    "\n",
    "for i in range(normalized_blocks.shape[0]):\n",
    "    img = pc_util.point_cloud_three_views(normalized_blocks[i,:,:])\n",
    "    filename = os.path.join('./images',source_file[i].split('.')[0]+'.jpg')\n",
    "    imageio.imwrite(filename,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
